{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape((-1, 28*28))\n",
    "x_test = x_test.reshape((-1, 28*28))\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [1, 10, 100]\n",
    "epochs_list = [10, 50, 100]\n",
    "learning_rate = 0.1\n",
    "hidden_units = 256\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Loop through all combinations\n",
    "for batch_size in batch_sizes:\n",
    "    for epochs in epochs_list:\n",
    "        print(f\"Training with batch size = {batch_size}, epochs = {epochs}\")\n",
    "\n",
    "        # Build model\n",
    "        model = models.Sequential([\n",
    "            layers.Input(shape=(784,)),\n",
    "            layers.Dense(hidden_units, activation='relu'),\n",
    "            layers.Dense(hidden_units, activation='relu'),\n",
    "            layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        optimizer = optimizers.SGD(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Time tracking\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=0,\n",
    "                            validation_data=(x_test, y_test))\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(x_test, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        acc = accuracy_score(y_test, y_pred_classes)\n",
    "        cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "        print(f\"Accuracy: {acc*100:.2f}% | Time Taken: {duration:.2f} seconds\")\n",
    "\n",
    "        # Save plots\n",
    "        suffix = f\"bs{batch_size}_ep{epochs}\"\n",
    "\n",
    "        # Accuracy & Loss Curve\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "        plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "        plt.title(f'Accuracy Curve ({suffix})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title(f'Loss Curve ({suffix})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"accuracy_loss_{suffix}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Confusion Matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
    "        plt.title(f'Confusion Matrix ({suffix})')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(f\"confusion_matrix_{suffix}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Append results\n",
    "        results.append({\n",
    "            'Batch Size': batch_size,\n",
    "            'Epochs': epochs,\n",
    "            'Accuracy': round(acc * 100, 2),\n",
    "            'Time (s)': round(duration, 2),\n",
    "            'Final Loss': round(history.history['val_loss'][-1], 4),\n",
    "            'Final Accuracy': round(history.history['val_accuracy'][-1], 4)\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"experiment_results.csv\", index=False)\n",
    "print(\"\\nAll experiment results saved to 'experiment_results.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
