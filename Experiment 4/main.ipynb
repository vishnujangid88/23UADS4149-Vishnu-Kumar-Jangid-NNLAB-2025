{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from openpyxl import Workbook\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "mnist = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "train_data, test_data = mnist\n",
    "\n",
    "def preprocess(images, labels):\n",
    "    images = tf.cast(images, tf.float32) / 255.0  # Normalize\n",
    "    images = tf.reshape(images, [784])  # Flatten\n",
    "    labels = tf.one_hot(labels, depth=10)  # One-hot encode\n",
    "    return images, labels\n",
    "\n",
    "batch_size_list = [1,10, 100]\n",
    "epochs_list = [10, 50,100]\n",
    "\n",
    "def train_and_evaluate(batch_size, epochs):\n",
    "    print(f\"\\nTraining with batch_size={batch_size}, epochs={epochs}\")\n",
    "\n",
    "    train_dataset = train_data.map(preprocess).batch(batch_size)\n",
    "    test_dataset = test_data.map(preprocess).batch(batch_size)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, 784])\n",
    "    Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([784, 128])),\n",
    "        'h2': tf.Variable(tf.random_normal([128, 64])),\n",
    "        'out': tf.Variable(tf.random_normal([64, 10]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([128])),\n",
    "        'b2': tf.Variable(tf.random_normal([64])),\n",
    "        'out': tf.Variable(tf.random_normal([10]))\n",
    "    }\n",
    "\n",
    "    def neural_network(x):\n",
    "        layer1 = tf.nn.relu(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "        layer2 = tf.nn.relu(tf.add(tf.matmul(layer1, weights['h2']), biases['b2']))\n",
    "        return tf.add(tf.matmul(layer2, weights['out']), biases['out'])\n",
    "\n",
    "    logits = neural_network(X)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "    predictions = tf.nn.softmax(logits)\n",
    "    correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    loss_curve, acc_curve, val_acc_curve = [], [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            avg_loss = 0\n",
    "            total_batches = 0\n",
    "            iterator = tf.compat.v1.data.make_one_shot_iterator(train_dataset)\n",
    "            next_batch = iterator.get_next()\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    batch_x, batch_y = sess.run(next_batch)\n",
    "                    _, c = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y})\n",
    "                    avg_loss += c\n",
    "                    total_batches += 1\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break  \n",
    "\n",
    "            avg_loss /= total_batches\n",
    "            train_acc = sess.run(accuracy, feed_dict={X: batch_x, Y: batch_y})\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "            loss_curve.append(avg_loss)\n",
    "            acc_curve.append(train_acc)\n",
    "            val_acc_curve.append(val_acc)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        test_acc = []\n",
    "        y_true, y_pred = [], []\n",
    "        iterator = tf.compat.v1.data.make_one_shot_iterator(test_dataset)\n",
    "        next_batch = iterator.get_next()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                batch_x, batch_y = sess.run(next_batch)\n",
    "                acc, preds = sess.run([accuracy, predictions], feed_dict={X: batch_x, Y: batch_y})\n",
    "                test_acc.append(acc)\n",
    "                y_pred.extend(np.argmax(preds, axis=1))\n",
    "                y_true.extend(np.argmax(batch_y, axis=1))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "        final_test_acc = np.mean(test_acc)\n",
    "        print(f\"Test Accuracy: {final_test_acc:.4f}\")\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(f\"Confusion Matrix (Batch={batch_size}, Epochs={epochs})\")\n",
    "        cm_filename = f\"confusion_matrix_batch{batch_size}_epochs{epochs}.png\"\n",
    "        plt.savefig(cm_filename)\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(loss_curve, label='Train Loss')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss Curve\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(acc_curve, label='Train Accuracy')\n",
    "        plt.plot(val_acc_curve, label='Val Accuracy')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Accuracy Curve\")\n",
    "\n",
    "        curve_filename = f\"curves_batch{batch_size}_epochs{epochs}.png\"\n",
    "        plt.savefig(curve_filename)\n",
    "        plt.close()\n",
    "\n",
    "    return batch_size, epochs, execution_time, final_test_acc, cm_filename, curve_filename\n",
    "\n",
    "results = []\n",
    "for batch_size in batch_size_list:\n",
    "    for epochs in epochs_list:\n",
    "        res = train_and_evaluate(batch_size, epochs)\n",
    "        results.append(res)\n",
    "\n",
    "df = pd.DataFrame(results, columns=['Batch Size', 'Epochs', 'Execution Time (s)', 'Test Accuracy', 'Confusion Matrix Image', 'Loss/Accuracy Curves'])\n",
    "df.to_excel(\"training_results.xlsx\", index=False)\n",
    "\n",
    "print(\"\\n All Results Saved in training_results.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
